#
  Copyright (C) 2025 by
  Dipl.-Ing. Michael Niederle

  This program is free software; you can redistribute it and/or modify
  it under the terms of the GNU General Public License, version 2, or
  (at your option) version 3.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
  GNU General Public License for more details.

  For details of the GNU General Public License see the accompanying
  files GPLv2.txt and GLPv3.txt or
  http://www.gnu.org/licenses/gpl-2.0.html
  http://www.gnu.org/licenses/gpl-3.0.html
  or write to the
  Free Software Foundation, Inc.,
  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.

<using std-2.0>
<using llama>
<using tedi>

<resolve std_types-2.0>

<allow unused>

$OPEN_MODEL .
$START_SERVER .
$TOKENIZE .
$CACHED_PREFIX .
$EVALUATE .
$AI .

!tedi::functions("ai_completion") tuple(ai_completion IO)

# Extending Existing Types

$is_a_space_token_of ()
$space_tokens_of ()
$period_token_of ()

$ai_types::model
  .period_token_of undefined
  .space_tokens_of undefined
  .is_a_space_token_of undefined

$ai_model_of ()
$initializing_ai_of ()
$ai_server_already_started_of ()

$tedi_types::state
  .ai_model_of undefined
  .initializing_ai_of false
  .ai_server_already_started_of false

$sequence_of ()

$tedi_types::page.sequence_of undefined

$id_of ()
$first_token_of ()
$last_token_of ()

$proto_sequence std_types::object
  .id_of undefined
  .tokens_of undefined

$tedi::tokens_of ()

$tedi_types::line
  .tokens_of undefined

# Defining New Types

$window_id_of ()
$at_line_start_of ()
$at_line_end_of ()
$tokenized_line_numbers_of ()
$tokenized_lines_of ()
$start_tokens_of ()
$additional_tokens_of ()
$start_length_of ()
$already_evaluated_prefix_length_of ()
$already_evaluated_count_of ()
$generated_token_count_of ()
$prefix_of ()
$pending_tokens_of ()
$total_token_count_of ()
$do_not_add_newline_of ()

$tedi_types::completion_job std_types::object
  .window_id_of undefined
  .at_line_start_of undefined
  .at_line_end_of undefined
  .x_of undefined
  .y_of undefined
  .tokenized_line_numbers_of undefined
  .tokenized_lines_of undefined
  .start_tokens_of undefined
  .additional_tokens_of undefined
  .tokens_of undefined
  .start_length_of undefined
  .already_evaluated_prefix_length_of undefined
  .already_evaluated_count_of undefined
  .generated_token_count_of undefined
  .prefix_of undefined
  .pending_tokens_of undefined
  .total_token_count_of undefined
  .do_not_add_newline_of undefined

# Editor Actions

$tedi::ai_completion: (io state x y _lines _info)
  if
    initializing_ai_of(state)
    -> io state
    :
      $configuration configuration_of(state)
      if
	configuration.is_undefined:
	  show_error_message &state OPEN_MODEL "initialization is not yet complete"
	  -> io state
	:
	  !state
	    .current_action_state_of RUNNING
	    .current_action_of
	      tedi_types::completion_job
		.window_id_of get_id(window_manager_of(state))
		.x_of x
		.y_of y
	  if
	    ai_model_of(state).is_undefined:
	      open_ai_model io state
	    :
	      start_completion io state

# AI Server Communication

$open_ai_model: (io state)
  $configuration configuration_of(state)
  $model_name ai_model_name_of(configuration)
  $address ai_server_address_of(configuration)
  $port_no ai_server_port_no_of(configuration)
  $message "opening model @(model_name) on @(address):@(port_no)"
  show_status_message &state OPEN_MODEL message
  log &io 2 message
  !state.initializing_ai_of true
  open_model &io OPEN_MODEL ai_model_name_of(configuration)
  -> io state

$OPEN_MODEL/job_failed: (_id io state _data _context)
  $configuration configuration_of(state)
  $model_name ai_model_name_of(configuration)
  $address ai_server_address_of(configuration)
  $port_no ai_server_port_no_of(configuration)
  $message "
    failed to open model @(model_name) on server @(address):@(port_no)
  show_error_message &state OPEN_MODEL message
  log &io message
  !state.initializing_ai_of false
  current_action_completed io state

$OPEN_MODEL/job_completed: (_id io state model _context)
  $configuration configuration_of(state)
  $model_name ai_model_name_of(configuration)
  $address ai_server_address_of(configuration)
  $port_no ai_server_port_no_of(configuration)
  $message "
    Opened model @(model_name) on server @(address):@(port_no)
  show_success_message &state OPEN_MODEL message
  !state.ai_model_of model
  !state.initializing_ai_of false
  if
    current_action_state_of(state) == CANCELLED:
      current_action_completed io state
    :
      start_completion io state

$start_completion: (io state)
  $completion_job current_action_of(state)
  $window_id window_id_of(completion_job)
  $model ai_model_of(state)
  $y y_of(completion_job)
  $lines range(lines_of(get_content(window_manager_of(state) window_id)) 1 -1)
  do:
    get_not_tokenized_lines $line_numbers $line_texts
    if
      line_numbers.is_not_empty:
	!state.current_action_of
	  completion_job
	    .tokenized_line_numbers_of line_numbers
	    .tokenized_lines_of empty_list
	$message "tokenizing @(length_of(line_numbers)) lines"
	show_status_message &state AI message
	log &io 2 message
	tokenize &io model line_texts
	-> io state
      :
	evaluate_text_lines io state

  $get_not_tokenized_lines:
    # ensure that line <y> has a single newline token at the end
    $line_numbers empty_list
    $line_texts empty_list
    for_each lines
      : (no line)
	if
	  line.is_undefined
	  next
	  :
	    if
	      tokens_of(line).is_defined
	      next
	      :
		push &line_numbers no
		$line_text
		  append
		    spaces(indent_of(line))
		    text_of(line)
		update_if no != y &line_text -> push(line_text '@nl;')
		push &line_texts line_text
		next
      -> line_numbers line_texts

$TOKENS/handle_event: (_type io state id tokens model)
  if
    current_action_state_of(state) == RUNNING:
      $completion_job current_action_of(state)
      $i length_of(tokenized_lines_of(completion_job))+1
      update_if
	tokenized_line_numbers_of(completion_job)(i) == y_of(completion_job)
	&tokens: push tokens nl_token_of(model)
      push &completion_job.tokenized_lines_of tokens
      if
	==
	  length_of(tokenized_lines_of(completion_job))
	  length_of(tokenized_line_numbers_of(completion_job))
	:
	  $window_id window_id_of(completion_job)
	  $page get_content(window_manager_of(state) window_id)
	  $tokenized_lines tokenized_lines_of(completion_job)
	  update_lines &page.lines_of tokenized_line_numbers_of(completion_job)
	    : (idx line) -> line(.tokens_of tokenized_lines(idx))
	  set_content &state.window_manager_of window_id page
	  evaluate_text_lines io state
	-> io state(.current_action_of completion_job)
    -> io state

$LOGITS/handle_event: (_type io state id logits model)
  show_status_message &state AI "inserting text"
  $completion_job current_action_of(state)
  $window_id window_id_of(completion_job)
  logits $seq_id !logits
  logits(1) $token
  detokenize model $piece token &completion_job.prefix_of
  update_if_not prefix_of(completion_job).is_empty
    &completion_job.pending_tokens_of
    -> push(pending_tokens_of(completion_job) token)
  !state.current_action_of completion_job
  if
    piece.is_empty
    continue_evaluation
    :
      if
	piece .contains. '@nl;':
	  remove_message &state.window_manager_of AI
	  truncate_from &piece '@nl;'
	  update_if_not piece.is_empty &state:
	    change_text state window_id insert INSERTION piece
	  if !state
	    do_not_add_newline_of(completion_job):
	      change_text &state window_id cursor_down MOVEMENT undefined
	      change_text state window_id tedi::cursor_home MOVEMENT undefined
	    :
	      change_text state window_id split_line INSERTION undefined
	  current_action_completed io state
	:
	  change_text &state window_id insert INSERTION piece
	  continue_evaluation

  $continue_evaluation:
    $page get_content(window_manager_of(state) window_id)
    push &page.sequence_of.tokens_of token
    set_content &state.window_manager_of page
    add_token_and_evaluate &io model seq_id token
    -> io state

$ERROR/handle_event: (_type io state _id err _model)
  $completion_job current_action_of(state)
  if
    completion_job.is_defined:
      show_error_message &state AI err
      current_action_completed io state
    -> io state # ignore follow up errors

$evaluate_text_lines: (io state)
  $completion_job current_action_of(state)
  $window_id window_id_of(completion_job)
  $ai_model ai_model_of(state)
  $page get_content(window_manager_of(state) window_id)
  $sequence sequence_of(page)
  if
    sequence.is_undefined:
      create_sequence &io ai_model window_id
      !sequence
	proto_sequence
	  .id_of window_id
      update_sequence
    update_sequence

  $update_sequence:
    $empty_line_tokens list(nl_token_of(ai_model))
    $x x_of(completion_job)
    $y y_of(completion_job)
    $lines lines_of(page)
    $len length_of(lines)
    $tokens
      map_reduce
	range(lines 1 min(y-1 len))
	: (line)
	  if
	    line.is_defined
	    -> tokens_of(line)
	    -> empty_line_tokens
	append
	empty_list
    update_if y > len &tokens:
      append tokens dup(list(nl_token_of(ai_model)) y-1-len)
    $cursor_line
      if
	y > len
	-> undefined
	-> lines(y)
    if !x !tokens
      cursor_line.is_defined && x > indent_of(cursor_line)+1:
	$line_tokens range(tokens_of(cursor_line) 1 -2) # remove newline token
	$width 0
	$prefix ""
	loop:
	  if
	    ||
	      line_tokens.is_empty
	      width+1 >= x && prefix.is_empty
	    -> width+1 tokens
	    :
	      $token line_tokens(1)
	      detokenize ai_model token $piece &prefix
	      plus &width width_of(piece)
	      push &tokens token
	      range &line_tokens 2 -1
	      next
      -> 1 tokens
    $do_not_add_newline cursor_line.is_defined && x == 1
    update_if do_not_add_newline &page &state:
      change_text &state window_id split_line INSERTION undefined
      change_text &state window_id cursor_up MOVEMENT undefined
      !page get_content(window_manager_of(state) window_id)
      -> page state
    goto_xy &page &state.window_manager_of window_id x y
    $seq_id id_of(sequence)
    if
      tokens_of(sequence).is_undefined:
	!sequence.tokens_of tokens
	evaluate_tokens
      :
	$sequence_tokens tokens_of(sequence)
	$n length_of(common_prefix(tokens sequence_tokens))
	if
	  n < length_of(sequence_tokens):
	    update_if n == length_of(tokens) &n -> n-1
	    truncate_sequence &io ai_model seq_id n
	    add_missing_tokens
	  add_missing_tokens

	$add_missing_tokens:
	  !sequence.tokens_of tokens
	  range &tokens n+1 -1
	  evaluate_tokens

    $evaluate_tokens:
      !page.sequence_of sequence
      !completion_job
	.prefix_of ""
	.pending_tokens_of empty_list
	.total_token_count_of length_of(tokens)
	.do_not_add_newline_of do_not_add_newline
      !state.current_action_of completion_job
      set_content &state.window_manager_of window_id page
      $message "evaluating @(total_token_count_of(completion_job)) tokens"
      show_status_message &state AI message
      log &io 4 message
      add_tokens &io ai_model seq_id tokens
      evaluate &io ai_model seq_id
      -> io state

$PROGRESS/handle_event: (_type io state _id data _model)
  data $_seq_id $remaining_tokens
  $completion_job current_action_of(state)
  $total_token_count total_token_count_of(completion_job)
  $already_done total_token_count-remaining_tokens
  show_progress_message &state AI already_done total_token_count
    "evaluating @(total_token_count) tokens"
  log &io 4 "evaluated @(already_done) of @(total_token_count) tokens"
  -> io state

$tedi::update_lines ()

$std_types::list/update_lines: (self line_numbers function)
  $updated_lines empty_list
  $last_updated_line_no 0
  for_each line_numbers
    : (idx line_no)
      $line self(line_no)
      append &updated_lines range(self last_updated_line_no+1 line_no-1)
      push &updated_lines function(idx line)
      !last_updated_line_no line_no
      next
    -> append(updated_lines range(self last_updated_line_no+1 -1))
