<html>
<head>
<title>ai_types::model/ai::generate</title>
<link rel="stylesheet" href="../../style.css">
</head>
<body>
<div>
<a class="Button" href="../../index.html">Home</a> <a class="Button" href="../../manual.html">Manual</a> <a class="Button" href="../../topics/index.html">Topics</a> <a class="Button" href="../type_index.html">Types</a> <a class="Button" href="../function_index.html">Functions</a> <a class="Button" href="../objects_index.html">Objects</a> <a class="Button" href="../constants_index.html">Constants</a> <a class="Button" href="../index.html">All</a>
</div>
<h1 class="pre">ai_types::model/ai::generate</h1>
<p class="short">generates text based on the specified prompt</p>
<h2>Parameters</h2>
<dl>
<dt>model</dt>
<dd>the model to use</dd>
<dt>options*</dt>
<dd>the options to use</dd>
<dt>prompt</dt>
<dd>the prompt to use</dd>
</dl>
<h2>Results</h2>
<dl>
<dt>the generated text</dt>
<dd></dd>
</dl>
<h2>Description</h2>
<p><em>Attention</em>: This function must be called with I/O-access rights!</p>
<p>The options are:</p>
<p>ai::MINIMUM_CONFIDENCE: the minimum confidence for a token to be accepted ai::MAXIMUM_LENGTH: the maximum length of the generated text ai::STOP: the text to stop generating at ai::BACKTRACK: the number of tokens to backtrack if the confidence is too low ai::LOG_LEVEL: the log level to use ai::VERBOSE: whether to print the generated text in verbose mode ai::USE_COLOURS: whether to use colours to indicate the confidence</p>
<p>The default values are:</p>
<p>ai::MINIMUM_CONFIDENCE: 15 ai::MAXIMUM_LENGTH: 1024 ai::STOP: undefined ai::BACKTRACK: 0 ai::LOG_LEVEL: 0 ai::VERBOSE: false ai::USE_COLOURS: false</p>
<p>The prompt is tokenized and then the tokens are evaluated using the model. The result is a list of tuples containing the token and the confidence. The token with the highest confidence is selected and appended to the generated text. This process is repeated until the maximum length is reached or the stop text is found.</p>
<h2>Topic</h2>
<table><tr><td><a href="../../topics/AI.html">AI</a></td></tr></table>
<h2>See also</h2>
<table>
<tr>
  <td><a href="../ai__evaluate.html">ai::evaluate</a></td>
  <td class="description">evaluates a prompt using a loaded AI model</td>
</tr>
<tr>
  <td><a href="../ai__tokenize.html">ai::tokenize</a></td>
  <td class="description">tokenizes a text string</td>
</tr>
<tr>
  <td><a href="../ai__detokenize.html">ai::detokenize</a></td>
  <td class="description">detokenizes a token or a list of tokens</td>
</tr>
</table>
<h2>Base Object</h2>
<table>
<tr>
<td><a href="../ai_types__model.html">ai_types::model</a></td>
<td class="description">the prototype object for all AI models</td>
</tr>
</table>
<h2>Implements</h2>
<table>
<tr>
<td><a href="../ai__generate.html">ai::generate</a></td>
<td class="description">generates text from a prompt</td>
</tr>
</table>
<div class="footer">(defined in <a href="../../source/ai/llama.fky">ai/llama.fky</a>)</div>
<div class="footer">(generated by Codestral-22B-v0.1-Q5_K_M.gguf)</div>
<div class="footer">(2024-07-03 16:01:07)</div>
<div class="footer">(<a href="../../prompts/symbols/ai_types__model/ai__generate.prompt">prompt</a>)</div>
</body>
</html>
