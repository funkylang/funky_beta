<html>
<head>
<title>ai::generate</title>
<link rel="stylesheet" href="../style.css">
</head>
<body>
<div>
<a class="Button" href="../index.html">Home</a> <a class="Button" href="../manual.html">Manual</a> <a class="Button" href="../topics/index.html">Topics</a> <a class="Button" href="type_index.html">Types</a> <a class="Button" href="function_index.html">Functions</a> <a class="Button" href="objects_index.html">Objects</a> <a class="Button" href="constants_index.html">Constants</a> <a class="Button" href="index.html">All</a>
</div>
<h1 class="pre">ai::generate</h1>
<p class="short">generates text from a prompt</p>
<h2>Parameters</h2>
<dl>
<dt>model</dt>
<dd>the AI model to use</dd>
<dt>options</dt>
<dd>a list of options</dd>
<dt>ai::MINIMUM_CONFIDENCE</dt>
<dd>the minimum confidence score required for a token to be included in the generated text</dd>
<dt>ai::MAXIMUM_LENGTH</dt>
<dd>the maximum length of the generated text</dd>
<dt>ai::STOP</dt>
<dd>a string that will stop the generation process</dd>
<dt>ai::BACKTRACK</dt>
<dd>the number of tokens to backtrack if the generation process gets stuck</dd>
<dt>ai::LOG_LEVEL</dt>
<dd>the level of logging to use</dd>
<dt>ai::VERBOSE</dt>
<dd>whether to print verbose output</dd>
<dt>ai::USE_COLOURS</dt>
<dd>whether to use colours in the output</dd>
<dt>prompt</dt>
<dd>the text to generate from</dd>
</dl>
<h2>Result</h2>
<dl>
<dt>text</dt>
<dd>the generated text</dd>
</dl>
<h2>Example</h2>
<div class="Example">&lt;require basic/stdlib&gt;
&lt;require basic/uuid&gt;
&lt;require basic/export/json&gt;
&lt;require basic/import/json&gt;
&lt;require ai/llama&gt;
&lt;require web/server&gt;

<a href="std__generate_uuid.html">generate_uuid</a>! $uuid <a href="std__undefined.html">undefined</a>
<a href="ai__load_ai_model.html">ai::load_ai_model</a>! $model modelname # assumes an already running AI-server
  <a href="std__UUID.html">UUID</a> = uuid
  <a href="ai__CONTEXT_SIZE.html">ai::CONTEXT_SIZE</a> = 4096
<a href="std__print.html">print</a>! prompt
<a href="ai__tokenize.html">ai::tokenize</a>! $tokens model prompt
<a href="std__repeat.html">repeat</a> 10 # generate 10 tokens
  :
    <a href="ai__evaluate.html">ai::evaluate</a>! $token model tokens
    $piece <a href="ai__detokenize.html">ai::detokenize</a>(model token)
    <a href="std__print.html">print</a>! piece
    <a href="std__push.html">push</a> &tokens token
    <a href="std__next.html">next</a>!
  :
    <a href="ai__deregister.html">ai::deregister</a>! uuid # deregister from the AI-server

$modelname "sauerkrautrlm-una-solar-instruc.Q5_K_M.gguf"
$prompt "Once upon a time"
</div>
<h2>Output</h2>
<div class="Output">Once upon a time, there was a beautiful princess named Aurora.
</div>
<h2>Topic</h2>
<table><tr><td><a href="../topics/AI.html">AI</a></td></tr></table>
<h2>See also</h2>
<table>
<tr>
  <td><a href="ai__tokenize.html">ai::tokenize</a></td>
  <td class="description">tokenizes a text string</td>
</tr>
<tr>
  <td><a href="ai__evaluate.html">ai::evaluate</a></td>
  <td class="description">evaluates a prompt using a loaded AI model</td>
</tr>
<tr>
  <td><a href="ai__detokenize.html">ai::detokenize</a></td>
  <td class="description">detokenizes a token or a list of tokens</td>
</tr>
</table>
<h2>Implementations</h2>
<table>
<tr>
<td><a href="ai_types__model/ai__generate.html">ai_types::model</a></td>
<td class="description">generates text based on the specified prompt</td>
</tr>
</table>
<div class="footer">(defined in <a href="../source/ai/llama.fky">ai/llama.fky</a>)</div>
<div class="footer">(generated by gemma-2-27b-it-Q5_K_M.gguf)</div>
<div class="footer">(2024-07-03 22:36:52)</div>
<div class="footer">(<a href="../prompts/symbols/ai__generate.prompt">prompt</a>)</div>
</body>
</html>
