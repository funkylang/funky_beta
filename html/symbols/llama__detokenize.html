<!doctype html>
<html>
<head>
<title>llama::detokenize</title>
<link rel="stylesheet" href="../style.css">
</head>
<body>
<div>
<a class="Button" href="../index.html">Home</a> <a class="Button" href="../manual.html">Manual</a> <a class="Button" href="../topics/index.html">Topics</a> <a class="Button" href="type_index.html">Types</a> <a class="Button" href="function_index.html">Functions</a> <a class="Button" href="objects_index.html">Objects</a> <a class="Button" href="constants_index.html">Constants</a> <a class="Button" href="index.html">All</a>
</div>
<h1 class="pre">llama::detokenize</h1>
<p class="short">converts a list of tokens into a string</p>
<h2>Parameters</h2>
<dl>
<dt>model</dt>
<dd>the model that was used to tokenize the string</dd>
<dt>tokens</dt>
<dd>the list of tokens</dd>
</dl>
<h2>Result</h2>
<dl>
<dt>the string that was tokenized</dt>
<dd></dd>
</dl>
<h2>Topic</h2>
<table><tr><td><a href="../topics/AI.html">AI</a></td></tr></table>
<h2>See also</h2>
<table>
<tr>
  <td><a href="llama__tokenize.html">llama::tokenize</a></td>
  <td class="description">tokenizes the specified prompt</td>
</tr>
</table>
<h2>Example</h2>
<pre class="Example">$model <a href="llama__open_model.html">llama::open_model</a>("llama-2-7b-chat.ggmlv3.q4_0.bin")
$tokens <a href="llama__tokenize.html">llama::tokenize</a>(model "Hello, World!")
$str <a href="llama__detokenize.html">llama::detokenize</a>(model tokens)
<a href="std__println.html">println</a>! str
</pre>
<h2>Output</h2>
<pre class="Output">Hello, World!
</pre>
<div class="footer">(defined in <a href="../source/ai/new_llama.fky">ai/new_llama.fky</a>)</div>
<div class="footer">(generated by Codestral-22B-v0.1-Q5_K_M.gguf)</div>
<div class="footer">(2025-04-20 9:59:03)</div>
</body>
</html>
