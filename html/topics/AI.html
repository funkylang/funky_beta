<!doctype html>
<html>
<head>
<title>AI</title>
<link rel="stylesheet" href="../style.css">
</head>
<body>
<div>
<a class="Button" href="../index.html">Home</a> <a class="Button" href="../manual.html">Manual</a> <a class="Button" href="index.html">Topics</a> <a class="Button" href="../symbols/type_index.html">Types</a> <a class="Button" href="../symbols/function_index.html">Functions</a> <a class="Button" href="../symbols/objects_index.html">Objects</a> <a class="Button" href="../symbols/constants_index.html">Constants</a> <a class="Button" href="../symbols/index.html">All</a>
</div>
<h1>AI</h1>
<h2>Description</h2>
<p>Funky currently supports large language models based on the llama.cpp project.</p>
<p>The "fllama" tool is a server program that must be started first before a client can send queries to the server.</p>
<p>A short glossary:</p>
<ul>
<li>An <i>LLM</i> is a Large Language Model.
</ul>
<ul>
<li>A <i>modelname</i> is the name of an LLM in GGUF-format including the ".gguf" file extension.
</ul>
<ul>
<li>A <i>model</i> is an object (<a href="../symbols/llama_types__model.html">llama_types::model</a>) on the client side that represents an LLM.
</ul>
<ul>
<li>A <i>token</i> is a non-negative integer number that represents one ore more (maybe partial) characters.
</ul>
<ul>
<li>A <i>piece</i> is a raw octet string associated with a token. This string can contain partial UTF-8-sequences. Most models do not contain so many tokens to be able to encode all possible Unicode code points. So smileys might be represented by two tokens each describing a part of a single code point.
</ul>
<ul>
<li>A <i>sequence</i> is a sequence of tokens stored on the server. Such a sequence contains prompts (supplied by the client) and answers (generated by the server). Sequences can be truncated, some tokens can be deleted or new tokens can be inserted. This might harm the quality of later evaluations because of rounding errors. Sequences can also be copied to share a common prefix string (e.g. some instructions) with each other.
</ul>
<ul>
<li>A <i>sequence-id</i> is a client supplied non-negative integer used to identify a sequence.
</ul>
<ul>
<li><i>logits</i> are float values that describe how good a token is suited to continue a sequence. The higher the value the better the token represents the "inner state" of the model. Logit values are logarithmic, so a slightly higher value represents a much better match. The absolute value of logits are model dependent.
</ul>
<ul>
<li><i>Tokenization</i> is the conversion of a text string into tokens.
</ul>
<ul>
<li><i>Detokenization</i> is the conversion of tokens into a text stringl
</ul>
<ul>
<li><i>Evaluation</i> is the generation of a list of logits to choose from for the next token based on the tokens already in the sequence
</ul>
<h2>Example</h2>
<pre class="Example">&lt;require basic/stdlib&gt;
&lt;require ai/new_llama&gt;

&lt;using std&gt;
&lt;using llama&gt;

$MODEL_NAME "sauerkrautlm-una-solar-instruct.Q5_K_M.gguf"
$PROMPT "Once upon a time"

$SEQ_ID 1
<a href="../symbols/llama__open_model.html">open_model</a>! $model MODEL_NAME
<a href="../symbols/llama__tokenize.html">tokenize</a>! $tokens model PROMPT
<a href="../symbols/llama__create_sequence.html">create_sequence</a>! model SEQ_ID
<a href="../symbols/llama__add_tokens.html">add_tokens</a>! model SEQ_ID <a href="../symbols/std__list.html">list</a>(<a href="../symbols/llama__bos_token_of.html">bos_token_of</a>(model))
<a href="../symbols/llama__add_tokens.html">add_tokens</a>! model SEQ_ID tokens
<a href="../symbols/llama__evaluate.html">evaluate</a>! model SEQ_ID
$prefix ""
<a href="../symbols/std__print.html">print</a>! PROMPT
<a href="../symbols/std__repeat.html">repeat</a> 20:
  <a href="../symbols/llama__get_logits.html">get_logits</a>! $_seq_id $_position $logits model
  logits(1) $best_token $_best_logit
  <a href="../symbols/llama__detokenize.html">detokenize</a> model best_token $piece &prefix
  <a href="../symbols/std__print.html">print</a>! piece
  <a href="../symbols/llama__add_token_and_evaluate.html">add_token_and_evaluate</a>! model SEQ_ID best_token
  <a href="../symbols/std__next.html">next</a>!
<a href="../symbols/std__println.html">println</a>!
</pre>
<h2>Output</h2>
<pre class="Output">Once upon a time, there was a little girl named Alice. Alice lived in a
small village with her parents and her
</pre>
<h2>Types</h2>
<table>
<tr>
  <td><a href="../symbols/llama_types__model.html">llama_types::model</a></td>
  <td class="description">the prototype object for all models</td>
</tr>
</table>
<h2>Functions</h2>
<table>
<tr>
  <td><a href="../symbols/llama__add_token_and_evaluate.html">llama::add_token_and_evaluate</a></td>
  <td class="description">adds a token and evaluates the sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__add_tokens.html">llama::add_tokens</a></td>
  <td class="description">adds tokens to a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__bos_token_of.html">llama::bos_token_of</a></td>
  <td class="description">the begin of sentence token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__copy_sequence.html">llama::copy_sequence</a></td>
  <td class="description">copies a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__create_sequence.html">llama::create_sequence</a></td>
  <td class="description">creates a new sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__delete_sequence.html">llama::delete_sequence</a></td>
  <td class="description">deletes a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__delete_tokens.html">llama::delete_tokens</a></td>
  <td class="description">deletes tokens from a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__detokenize.html">llama::detokenize</a></td>
  <td class="description">converts a list of tokens into a string</td>
</tr>
<tr>
  <td><a href="../symbols/llama__eos_token_of.html">llama::eos_token_of</a></td>
  <td class="description">the end-of-sequence token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__eot_token_of.html">llama::eot_token_of</a></td>
  <td class="description">the end-of-text token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__evaluate.html">llama::evaluate</a></td>
  <td class="description">evaluates a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__fd_of.html">llama::fd_of</a></td>
  <td class="description">the file descriptor of the model</td>
</tr>
<tr>
  <td><a href="../symbols/llama__get_logits.html">llama::get_logits</a></td>
  <td class="description">returns the logits for the next token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__insert_tokens.html">llama::insert_tokens</a></td>
  <td class="description">inserts tokens into a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/llama__list_models.html">llama::list_models</a></td>
  <td class="description">lists the available models</td>
</tr>
<tr>
  <td><a href="../symbols/llama__nl_token_of.html">llama::nl_token_of</a></td>
  <td class="description">the newline token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__open_model.html">llama::open_model</a></td>
  <td class="description">opens a model</td>
</tr>
<tr>
  <td><a href="../symbols/llama__pad_token_of.html">llama::pad_token_of</a></td>
  <td class="description">the pad token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__sep_token_of.html">llama::sep_token_of</a></td>
  <td class="description">the separator token</td>
</tr>
<tr>
  <td><a href="../symbols/llama__tokenize.html">llama::tokenize</a></td>
  <td class="description">tokenizes the specified prompt</td>
</tr>
<tr>
  <td><a href="../symbols/llama__truncate_sequence.html">llama::truncate_sequence</a></td>
  <td class="description">truncates a sequence</td>
</tr>
<tr>
  <td><a href="../symbols/std__address_of.html">std::address_of</a></td>
  <td class="description">returns the address of the object</td>
</tr>
</table>
<div class="footer">(defined in <a href="../source/ai/new_llama.fky">ai/new_llama.fky</a>)</div>
</body>
</html>
