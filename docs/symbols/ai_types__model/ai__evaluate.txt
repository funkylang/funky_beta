# ai_types::model/ai::evaluate (an I/O-method)

  evaluates the specified prompt using the specified model

  Parameters:
    model: the model to use
    prompt: the prompt to evaluate
    mode: the mode to use (default: ai::SMART)
    start: the start position (default: 0)

  Results:
    if result_count() == 1:
      the token with the highest confidence
    if result_count() == 2:
      the token with the highest confidence and the confidence values

  **Attention**: This function must be called with I/O-access rights!

  The prompt is tokenized and evaluated using the specified model.

  The mode parameter can be one of the following:

    ai::EXACT: evaluate the result using the full context size (slow)
    ai::SMART: evaluate the result using a smaller context size (fast)

  The start parameter can be used to specify the start position of the
  evaluation.

  Topic: Deprecated AI

  See also: ai::tokenize, ai::detokenize, ai::generate

((defined in ai/llama.fky))
((generated by Codestral-22B-v0.1-Q5_K_M.gguf))
((2024-07-03 16:02:27))
