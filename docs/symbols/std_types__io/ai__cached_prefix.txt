# std_types::io/ai::cached_prefix (a method)

  calculates the length of the cached prefix

  Parameters:
    io: the I/O-object
    id: the job id
    model: the model to use
    prompt: the prompt to use
    mode: the mode to use
    start: the start position
    additional: the additional length

  Results:
    cached_prefix_length: the length of the cached prefix
    additional_length: the additional length

  Calculates the length of the cached prefix for the specified prompt and
  mode.

  The result is returned as a job.

  Topic: Deprecated AI

  See also: ai::evaluate, ai::tokenize

((defined in ai/llama.fky))
((generated by Codestral-22B-v0.1-Q5_K_M.gguf))
((2024-12-09 21:20:52))
