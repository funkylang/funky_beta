# std_types::io/llama::delete_tokens (a method)

  deletes tokens from a sequence

  Parameters:
    io: the I/O-object to use
    model: the model to use
    sequence_id: the sequence to modify
    position: the position of the first token to delete
    token_count: the number of tokens to delete

  Result:
    none

  Deletes the specified number of tokens from the specified sequence.

  Topic: AI

  See also: llama::delete_sequence, llama::truncate_sequence,
            llama::insert_tokens, llama::add_tokens

((defined in ai/new_llama.fky))
((generated by Codestral-22B-v0.1-Q5_K_M.gguf))
((2025-04-20 10:03:37))
