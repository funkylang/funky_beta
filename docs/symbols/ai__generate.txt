# ai::generate (a polymorphic function)

  generates text from a prompt

  Parameters:
    model: the AI model to use
    options: a list of options
      ai::MINIMUM_CONFIDENCE: the minimum confidence score required for a token to be included in the generated text
      ai::MAXIMUM_LENGTH: the maximum length of the generated text
      ai::STOP: a string that will stop the generation process
      ai::BACKTRACK: the number of tokens to backtrack if the generation process gets stuck
      ai::LOG_LEVEL: the level of logging to use
      ai::VERBOSE: whether to print verbose output
      ai::USE_COLOURS: whether to use colours in the output
    prompt: the text to generate from

  Result:
    text: the generated text

  Example:

    <require basic/stdlib>
    <require basic/uuid>
    <require basic/export/json>
    <require basic/import/json>
    <require ai/llama>
    <require web/server>

    generate_uuid! $uuid undefined
    ai::load_ai_model! $model modelname # assumes an already running AI-server
      UUID = uuid
      ai::CONTEXT_SIZE = 4096
    print! prompt
    ai::tokenize! $tokens model prompt
    repeat 10 # generate 10 tokens
      :
	ai::evaluate! $token model tokens
	$piece ai::detokenize(model token)
	print! piece
	push &tokens token
	next!
      :
	ai::deregister! uuid # deregister from the AI-server

    $modelname "sauerkrautrlm-una-solar-instruc.Q5_K_M.gguf"
    $prompt "Once upon a time"

  Output:

    Once upon a time, there was a beautiful princess named Aurora.

  Topic: Deprecated AI

  See also: ai::tokenize, ai::evaluate, ai::detokenize

((defined in ai/llama.fky))
((generated by gemma-2-27b-it-Q5_K_M.gguf))
((2024-07-03 22:36:52))
