# llama_types::model/llama::copy_sequence (an I/O-method)

  copies a sequence from a model

  Parameters:
    model: the model to copy the sequence from
    sequence_id: the id of the sequence to copy
    template_id: the id of the template sequence to copy from
    token_count: the number of tokens to copy

  Results:
    none

  **This function must be called with I/O-access rights!**

  **Attention**: The template sequence must be already evaluated!

  This function creates a copy of the server stored sequence with the id
  *template_id*. The new sequence is stored on the server with the id
  *sequence_id*. The sequence is copied from the beginning of the template
  sequence up to the *token_count*'th token.

  A big advantage of copying an existing sequence is that the new sequence
  shares cached state with the (start of the) template sequence.

  This can be used to add one and the same instructions to multiple prompts
  which are then evaluated in parallel.

  Topic: AI

  See also: llama::copy_sequence, llama::delete_sequence,
	    llama::truncate_sequence

  Example:

    <require basic/stdlib>
    <require ./ai/new_llama>

    <using std>
    <using llama>

    $TEMPLATE_ID 0
    $SEQ_ID 1

    open_model! $model "sauerkrautlm-una-solar-instruct.Q5_K_M.gguf"
    tokenize! $template_tokens model "This is a ..."
    create_sequence! model TEMPLATE_ID
    add_tokens! model TEMPLATE_ID template_tokens
    evaluate! model TEMPLATE_ID

    copy_sequence! model SEQ_ID TEMPLATE_ID length_of(template_tokens)

    tokenize! $query_tokens model "Who was ...?"
    add_tokens model SEQ_ID query_tokens
    evaluate! model SEQ_ID

((defined in ai/new_llama.fky))
((generated by Codestral-22B-v0.1-Q5_K_M.gguf))
((revised))
((2025-04-20 10:00:05))
