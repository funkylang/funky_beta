[MANUAL]

In Funky function calls are either written on a single line with arguments
enclosed within parentheses and separated by single spaces, e.g.:

print! f(a b c) g(x y z)

or they are written in indentation style using mutliple lines:

print!
  f
    a
    b
    c
  g
    x
    y
    z

Functions that create any output or read any input need I/O-access rights.

A function that needs I/O-access rights must be called with a trailing
exclamation mark after the function name, e.g.:

println! "Hello, World!"

The expression

key = value

denotes a key-value-pair.

Collection types cannot be printed directly. You can use "dump!" to
dump the contents of a collection, e.g.:

$ages
  hash_table
    "John" = 42
    "Mary" = 25
    "Irene" = 49

dump! `ages

Output:

ages: hash_table <6>
  "Mary"
  25
  "Irene"
  49
  "John"
  42

Note: The number in angular brackets after the typename denotes the number
of (indented) lines that follow the head.

A tail call returns the result of the called function; e.g.:

$calc:
  (
    x
    y
  )
  plus x*x y*y

println! calc(2 3)

prints

13

[GUIDELINES]

All documentation remarks must have

* a single short (single line) description written in lower case

* a parameter(s) section (if appropriate)

* a result(s) section (if appropriate)

* a detailed description of how to use the symbol: when describing unique
  items of constants, describe how to use them;
  do not repeat yourself

* one or more associated topic(s) (if appropriate)

* a "See also" entry - mention only a view relevant symbols here

Do not mention unknown symbols!

Do not mention more than 10 symbols in the "See also" entry.

DO NOT MENTION MORE THAN 10 SYMBOLS IN THE "See also" ENTRY!

Do not mention internal details of functions.

Do not start each sentence in the description with "If" or "The".

DO NOT START EACH SENTENCE IN THE DESCRIPTION WITH "If" OR "The"!

Do not tell the user what a function does not do.

When referring to another symbol write it enclosed in angle brackets, e.g.
<std::clear>.

The "self"-parameter is a normal parameter like any other and should be
mentioned in the the parameter description.

Replace symbolic constants by their value.

Operations on I/O-objects are not executed immediately but queued as jobs.
To identify a job, an "id" is used.

I/O-functions and I/O-methods either need I/O-access rights or propagate
them ("if", "for_each", etc.).

An "example" section, if available, must use Funky syntax and shall not be too
long.

If there is an appropriate example in the source code then use this example
in the "example" section!

[EXAMPLES]

[source]

$std::clear_colour_of ()

[documentation remark]

# std::clear_colour_of (a polymorphic function)

  the clear colour to use

  Parameter:
    self: the object from which to get the clear colour

  Result:
    colour: the clear colour

  Returns the clear colour of the object.

  Topic: Terminal

  See also: std::draw_colour_of, std::set_clear_colour

[source]

$std_types::screen/clear:
  (
    self
    x = 1
    y = 1
    width = undefined
    height = undefined
  )
  update_if width.is_undefined &width -> width_of(self)-x+1
  update_if height.is_undefined &height -> height_of(self)-y+1
  basic_private::clear self self x y width height

$std::clear ()

[documentation remark]

# std::clear (a polymorphic function)

  clears a rectangular area

  Parameters:
    screen: some kind of screen
    x: x-coordinate of the upper left corner
    y: y-coordinate of the upper left corner
    width: width of the area
    height: height of the area

  Result:
    screen: the updated screen

  The area is cleared using the current clear colour. Use
  <std::set_clear_colour> to change the current clear colour.

  The area is clipped at the screen's borders.

  Topic: Terminal

  See also: std_types::screen/std::clear, std::draw_text,
            std::set_clear_colour

  Example:

    $my_screen create_screen(terminal 40 25)
    set_clear_colour &my_screen GREEN
    clear &my_screen 11 6 20 15

[EXERCISE]

#
  Topic: AI

  Funky currently supports large language models based on the llama.cpp project.

  A "piece" is the string associated with a token.

  Example:

    <require basic/stdlib>
    <require basic/uuid>
    <require basic/export/json>
    <require basic/import/json>
    <require ai/llama>
    <require web/server>

    generate_uuid! $uuid undefined
    ai::load_ai_model! $model modelname # assumes an already running AI-server
      UUID = uuid
      ai::CONTEXT_SIZE = 4096
    print! prompt
    ai::tokenize! $tokens model prompt
    repeat 10 # generate 10 tokens
      :
        ai::evaluate! $token model tokens
        $piece ai::detokenize(model token)
        print! piece
        push &tokens token
        next!
      :
        ai::deregister! uuid # deregister from the AI-server

    $modelname "sauerkrautlm-una-solar-instruct.Q5_K_M.gguf"
    $prompt "Once upon a time"

  Output:

    Once upon a time, there was a beautiful princess named Aurora.

[symbols]


# Modes

$ai::EXACT . # evaluate the result using the full context size (slow)
$ai::SMART .

# Attributes

$ai::pieces_of ()
$ai::piece_table_of ()
$ai::maximum_piece_length_of ()
$ai::begin_of_stream_token_of ()
$ai::end_of_stream_token_of ()
$ai::classsification_token_of ()
$ai::separator_token_of ()
$ai::newline_token_of ()
$ai::space_token_of ()
$ai::end_of_text_token_of ()
$ai::prefix_token_of ()
$ai::suffix_token_of ()
$ai::middle_token_of ()
$ai::question_token_of ()
$ai::answer_token_of ()
$ai::context_size_of ()
$ai::effective_context_size_of ()
$std::address_of ()
$std::port_no_of ()

# Methods

$ai::cached_prefix ()
$ai::evaluate ()
$ai::tokenize ()
$ai::detokenize ()
$ai::generate ()
$ai::deregister ()

# Options

$ai::SERVER_NAME .
$ai::CONTEXT_SIZE .
$ai::MODEL_PATH .
$ai::MINIMUM_CONFIDENCE .
$ai::MAXIMUM_LENGTH .
$ai::STOP .
$ai::BACKTRACK .
$ai::LOG_LEVEL .
$ai::VERBOSE .
$ai::USE_COLOURS .

# Prototype Objects

$ai_types::connection std_types::resource
$std_types::object.is_a_connection false
$ai_types::connection.is_a_connection true
$ai_types::connection.address_of undefined
$ai_types::connection.port_no_of undefined
$ai_types::connection.uuid_of undefined
$ai_types::connection.name_of "connection"
$ai_types::connection/finalize:
$ai_types::model std_types::object
$ai_types::model.name_of undefined
$ai_types::model.address_of undefined
$ai_types::model.port_no_of undefined
$ai_types::model.uuid_of undefined
$ai_types::model.ai::pieces_of undefined
$ai_types::model.ai::piece_table_of undefined
$ai_types::model.ai::maximum_piece_length_of undefined
$ai_types::model.ai::begin_of_stream_token_of undefined
$ai_types::model.ai::end_of_stream_token_of undefined
$ai_types::model.ai::classsification_token_of undefined
$ai_types::model.ai::separator_token_of undefined
$ai_types::model.ai::newline_token_of undefined
$ai_types::model.ai::space_token_of undefined
$ai_types::model.ai::end_of_text_token_of undefined
$ai_types::model.ai::prefix_token_of undefined
$ai_types::model.ai::suffix_token_of undefined
$ai_types::model.ai::middle_token_of undefined
$ai_types::model.ai::question_token_of undefined
$ai_types::model.ai::answer_token_of undefined
$ai_types::model.ai::context_size_of undefined
$ai_types::model.ai::effective_context_size_of undefined

# Implementation

$ai::list_ai_models:
$ai::load_ai_model ()
$std_types::string/ai::load_ai_model:
$std_types::io.model_of empty_hash_table
$std_types::io/ai::load_ai_model:
$ai_types::model/ai::generate:
$ai_types::model/ai::tokenize:
$std_types::io/ai::tokenize:
$ai_types::model/ai::evaluate:
$std_types::io/ai::evaluate:
$std_types::io/ai::cached_prefix:
$ai_types::model/ai::detokenize:
$ai::connect_to_ai_server:
$std_types::io.connection_of empty_hash_table
$std_types::string/ai::deregister:
$ai_types::model/ai::deregister:
$std_types::io/ai::deregister:
$ai::escaped_token: (model token)
$ai::escaped_piece: (piece)
$ai::start_ai_server: (io id options*)

#
  Copyright (C) 2023 by
  Dipl.-Ing. Michael Niederle

  This program is free software; you can redistribute it and/or modify
  it under the terms of the GNU Library General Public License, version 2, or
  (at your option) under the terms of the GNU Lesser General Public License,
  version 3.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
  GNU Lesser (Library) General Public License for more details.

  For details of the GNU General Public License see the accompanying
  files LGPLv2.txt and LGLPv3.txt or
  http://www.gnu.org/licenses/lgpl-2.0.html
  http://www.gnu.org/licenses/lgpl-3.0.html
  or print to the
  Free Software Foundation, Inc.,
  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.

<namespace ai>

<namespace ai_types>

#
  Topic: AI

  Funky currently supports large language models based on the llama.cpp project.

  A "piece" is the string associated with a token.

  Example:

    <require basic/stdlib>
    <require basic/uuid>
    <require basic/export/json>
    <require basic/import/json>
    <require ai/llama>
    <require web/server>

    generate_uuid! $uuid undefined
    ai::load_ai_model! $model modelname # assumes an already running AI-server
      UUID = uuid
      ai::CONTEXT_SIZE = 4096
    print! prompt
    ai::tokenize! $tokens model prompt
    repeat 10 # generate 10 tokens
      :
        ai::evaluate! $token model tokens
        $piece ai::detokenize(model token)
        print! piece
        push &tokens token
        next!
      :
        ai::deregister! uuid # deregister from the AI-server

    $modelname "sauerkrautlm-una-solar-instruct.Q5_K_M.gguf"
    $prompt "Once upon a time"

  Output:

    Once upon a time, there was a beautiful princess named Aurora.

# Modes

$ai::EXACT . # evaluate the result using the full context size (slow)

$ai::SMART .

$DEFAULT_PORT_NO 8080

# Attributes

$ai::pieces_of ()

$ai::piece_table_of ()

$ai::maximum_piece_length_of ()

$ai::begin_of_stream_token_of ()

$ai::end_of_stream_token_of ()

$ai::classsification_token_of ()

$ai::separator_token_of ()

$ai::newline_token_of ()

$ai::space_token_of ()

$ai::end_of_text_token_of ()

$ai::prefix_token_of ()

$ai::suffix_token_of ()

$ai::middle_token_of ()

$ai::question_token_of ()

$ai::answer_token_of ()

$ai::context_size_of ()

$ai::effective_context_size_of ()
  #
    the context size to effectively use with the model

    must be less or equal to <ai::context_size_of> (or <std::undefined>)

$std::address_of ()

$std::port_no_of ()

$uuid_of ()

# Methods

$ai::cached_prefix ()

$ai::evaluate ()

$ai::tokenize ()

$ai::detokenize ()

$ai::generate ()

$ai::deregister ()

# Options

$ai::SERVER_NAME .

$ai::CONTEXT_SIZE .

$ai::MODEL_PATH .

$ai::MINIMUM_CONFIDENCE .

$ai::MAXIMUM_LENGTH .

$ai::STOP .

$ai::BACKTRACK .

$ai::LOG_LEVEL .

$ai::VERBOSE .

$ai::USE_COLOURS .

# Prototype Objects

$ai_types::connection std_types::resource

$is_a_connection ()

$std_types::object.is_a_connection false

$ai_types::connection.is_a_connection true

$ai_types::connection.address_of undefined

$ai_types::connection.port_no_of undefined

$ai_types::connection.uuid_of undefined

$ai_types::connection.name_of "connection"

$DEREGISTER .

$ai_types::connection/finalize:
  (
    self
    io
  )
  $address address_of(self)
  $port_no port_no_of(self)
  $uuid uuid_of(self)
  $id tuple(DEREGISTER uuid)
  log &io 3 "deregistering from AI server at address @(address):@(port_no)"
  http_request! &io $_events id address port_no deregister_request(uuid)
  register_handlers io id
    JOB_COMPLETED = deregister_completed
    JOB_FAILED = deregister_failed

$deregister_completed: (io id _data)
  log &io 3 "successfully deregistered from AI server"
  deregister_all_handlers &io id
  -> io undefined

$deregister_failed: (io id _data)
  log &io "failed to deregister from AI server"
  deregister_all_handlers &io id
  -> io undefined

$ai_types::model std_types::object

$ai_types::model.name_of undefined

$ai_types::model.address_of undefined

$ai_types::model.port_no_of undefined

$ai_types::model.uuid_of undefined

$ai_types::model.ai::pieces_of undefined

$ai_types::model.ai::piece_table_of undefined

$ai_types::model.ai::maximum_piece_length_of undefined

$ai_types::model.ai::begin_of_stream_token_of undefined

$ai_types::model.ai::end_of_stream_token_of undefined

$ai_types::model.ai::classsification_token_of undefined

$ai_types::model.ai::separator_token_of undefined

$ai_types::model.ai::newline_token_of undefined

$ai_types::model.ai::space_token_of undefined

$ai_types::model.ai::end_of_text_token_of undefined

$ai_types::model.ai::prefix_token_of undefined

$ai_types::model.ai::suffix_token_of undefined

$ai_types::model.ai::middle_token_of undefined

$ai_types::model.ai::question_token_of undefined

$ai_types::model.ai::answer_token_of undefined

$ai_types::model.ai::context_size_of undefined

$ai_types::model.ai::effective_context_size_of undefined

# Implementation

$ai::list_ai_models:
  (
     options*
  )
  get_options options
    ADDRESS = "127.0.0.1" $address
    PORT_NO = DEFAULT_PORT_NO $port_no
    UUID = undefined $uuid
  $json
    to_json
      insert_order_table
        "uuid" = uuid
  to_utf8 &json
  open_tcp_client_socket! $fd address port_no
  write_to! fd "
    POST /list_models HTTP/1.1@cr;
    Content-Type: application/json@cr;
    Content-Length: @(length_of(json))@cr;
    Connection: close@cr;
    @cr;
    @(json)
  load! $result fd
  on result.is_an_error result
  behind &result "@cr;@nl;@cr;@nl;"
  from_utf8 &result
  $info result.from_json
  -> info("models")

$ai::load_ai_model ()

$std_types::string/ai::load_ai_model:
  (
    name
    options*
  )
  initialize_model $model name options
  get_tokens! model
    !model.ai::pieces_of
    !model.ai::begin_of_stream_token_of
    !model.ai::end_of_stream_token_of
    !model.ai::classsification_token_of
    !model.ai::separator_token_of
    !model.ai::newline_token_of
    !model.ai::end_of_text_token_of
    !model.ai::prefix_token_of
    !model.ai::suffix_token_of
    !model.ai::middle_token_of
    !model.ai::context_size_of
  if
    ai::pieces_of(model).is_an_error
    -> ai::pieces_of(model)
    :
      build_piece_table &model

      #
        The default special tokens are only meant to be used with LLama models
        So let's replace them for other models (especially Falcon).

      !model.ai::newline_token_of ai::piece_table_of(model)("@nl;")
      !model.ai::space_token_of ai::piece_table_of(model)(" ")

      for_each ai::pieces_of(model)
        : (token piece)
          if
            &&
              piece.is_a_string
              length_of(piece) > 4
              ||
                piece .has_prefix. "<|" && piece .has_suffix. "|>"
                piece .has_prefix. ">>" && piece .has_suffix. "<<"
            :
              $special range(piece 3 -3)
              case special
                "endoftext":
                  !model.ai::end_of_text_token_of token-1
                  next
                "QUESTION":
                  !model.ai::question_token_of token-1
                  next
                "ANSWER":
                  !model.ai::answer_token_of token-1
                  next
                "PREFIX":
                  !model.ai::prefix_token_of token-1
                  next
                "SUFFIX":
                  !model.ai::suffix_token_of token-1
                  next
                "MIDDLE":
                  !model.ai::middle_token_of token-1
                  next
                next
            next
        -> model

$model_of ()

$std_types::io.model_of empty_hash_table

$std_types::io/ai::load_ai_model:
  (
    io
    id
    name
    options*
  )
  update_if
    &&
      length_of(options) == 1
      ||
        options(1).is_a_list
        options(1).is_a_connection
    &options -> options(1)
  initialize_model $model name options
  tuple &id 1
  run &io http_request id
    address_of(model) port_no_of(model) get_tokens_request(model)
  !io.model_of(id) model
  register_handlers io id
    JOB_COMPLETED = load_ai_model_completed
    JOB_FAILED = load_ai_model_failed

$load_ai_model_completed: (io id data)
  $model model_of(io)(id)
  !io.model_of(id) undefined
  deregister_all_handlers &io id
  id !id
  from_utf8 &data
  from_json &data
  if
    data.is_an_error || data.is_undefined
    -> io tuple(JOB_FAILED id error(IO_ERROR "INVALID JSON"))
    :
      !model
        .ai::pieces_of data("tokens")
        .ai::begin_of_stream_token_of data("begin_of_stream")
        .ai::end_of_stream_token_of data("end_of_stream")
        .ai::classsification_token_of data("classification")
        .ai::separator_token_of data("separator")
        .ai::newline_token_of data("newline")
        .ai::end_of_text_token_of data("end_of_text")
        .ai::prefix_token_of data("prefix")
        .ai::suffix_token_of data("suffix")
        .ai::middle_token_of data("middle")
        .ai::context_size_of data("context_size")
      build_piece_table &model
      !model.ai::space_token_of ai::piece_table_of(model)(" ")
      -> io tuple(JOB_COMPLETED id model)

$load_ai_model_failed: (io id err)
  !io.model_of(id) undefined
  deregister_all_handlers &io id
  id !id
  -> io tuple(JOB_FAILED id err)

$initialize_model: (name options)
  if
    options.is_a_connection
    ->
      ai_types::model
        .name_of name
        .address_of address_of(options)
        .port_no_of port_no_of(options)
        .uuid_of uuid_of(options)
        .ai::effective_context_size_of undefined
    :
      get_options options
        ADDRESS = "127.0.0.1" $address
        PORT_NO = DEFAULT_PORT_NO $port_no
        UUID = undefined $uuid
        ai::CONTEXT_SIZE = undefined $context_size
      ->
        ai_types::model
          .name_of name
          .address_of address
          .port_no_of port_no
          .uuid_of uuid
          .ai::effective_context_size_of context_size

[source]

$std_types::io/ai::cached_prefix:
  (
    io
    id
    model
    prompt
    mode = ai::SMART
    start = 0
    additional = 0
  )
  tuple &id 1
  run &io http_request id
    address_of(model) port_no_of(model)
    cached_prefix_request(model prompt mode start additional)
  register_handlers io id
    JOB_COMPLETED = cached_prefix_completed
    JOB_FAILED = cached_prefix_failed

$ai::cached_prefix ()

[documentation remark]

### Always copy examples contained in the symbol's description remark
    into the documentation

### Use (parts of) the documentation already provided in the source

### Do not create completely new examples on your own

### Use only one of the following topics: AI

# ai::cached_prefix (a polymorphic function)

